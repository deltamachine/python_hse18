{
  "cells": [
    {
      "metadata": {
        "_uuid": "db8700dc9b8d1a1bb99ec8b34dcab9320516c2d8"
      },
      "cell_type": "markdown",
      "source": "# Assignment 7\n\nDelelop language model, which generates death metal band names.  \nYou can get data from https://www.kaggle.com/zhangjuefei/death-metal.  \nYou are free to use any other data, but the most easy way is just to take the band name column.\n\nYour language model should be char-based autogression RNN.  \nText generation should be terminated when either max length is reached or terminal symbol is generated.  \n\n<img src=\"images/example.png\">\n\n<img src=\"images/example2.png\">\n\nDifferent band names can be generated by:  \n1. init $h_0$ as random vector from some probabilty distribution.\n2. sampling over tokens at each timestep with probability = softmax \n\nCalculate perplexity for your model = your objective quality metric.  \nAlso, sample 10 band names from your model for subjective evaluation. E.g. names like 'qwiouefiou23riop2h3' or 'death death death!' are bad examples.  "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cd3c1bcda7efc8a8d4296e59a36e63b1616f8f97",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport random\nimport string\nimport torch as tt\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom tqdm.autonotebook import tqdm\n\nimport warnings\nwarnings.simplefilter('ignore')\n\nSEED = 42\nnp.random.seed(SEED)",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "357d7384f7c3c7ae67327a6bdf0e1ae074bd0eef"
      },
      "cell_type": "markdown",
      "source": "## Data"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8527d1dc8c9f5539161781ef27d94ec81490ce3f"
      },
      "cell_type": "code",
      "source": "df = pd.read_csv('../input/death-metal/bands.csv',  encoding='ISO-8859-1')\ndf.head()",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "   id                name      ...                theme        active\n0   1          ('M') Inc.      ...                  NaN        2009-?\n1   2               (sic)      ...                  NaN     1993-1996\n2   3           .F.O.A.D.      ...       Life and Death  2009-present\n3   4            100 Suns      ...                  NaN  2004-present\n4   5  12 Days of Anarchy      ...              Anarchy     1998-2002\n\n[5 rows x 8 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>country</th>\n      <th>status</th>\n      <th>formed_in</th>\n      <th>genre</th>\n      <th>theme</th>\n      <th>active</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>('M') Inc.</td>\n      <td>United States</td>\n      <td>Unknown</td>\n      <td>2009.0</td>\n      <td>Death Metal</td>\n      <td>NaN</td>\n      <td>2009-?</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>(sic)</td>\n      <td>United States</td>\n      <td>Split-up</td>\n      <td>1993.0</td>\n      <td>Death Metal</td>\n      <td>NaN</td>\n      <td>1993-1996</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>.F.O.A.D.</td>\n      <td>France</td>\n      <td>Active</td>\n      <td>2009.0</td>\n      <td>Death Metal</td>\n      <td>Life and Death</td>\n      <td>2009-present</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>100 Suns</td>\n      <td>United States</td>\n      <td>Active</td>\n      <td>2004.0</td>\n      <td>Death Metal</td>\n      <td>NaN</td>\n      <td>2004-present</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>12 Days of Anarchy</td>\n      <td>United States</td>\n      <td>Split-up</td>\n      <td>1998.0</td>\n      <td>Death Metal</td>\n      <td>Anarchy</td>\n      <td>1998-2002</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "f5ac258dc555d0eb77efce12c7ce547891efa1b2"
      },
      "cell_type": "markdown",
      "source": "Для увеличения шансов на успех выкинем те названия групп, в которых есть знаки препинания и всякие странные символы, оставим только названия с латинскими буквами и цифрами."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e676a45839e0147b5163e9d3124c891c4d644908"
      },
      "cell_type": "code",
      "source": "chars = ' ' + '0123456789' + string.ascii_letters",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8374484393d4b7d454a6c05a72c321ab43f82015"
      },
      "cell_type": "code",
      "source": "bands = []\n\nfor name in df['name']:\n    symbols = set(list(name))\n    \n    counter = 0\n    \n    for s in symbols:\n        if s not in chars:\n            counter = 1\n    \n    if counter == 0:\n        bands.append(name)",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d9142720301cc1f60ae63e0a2ad8eb7f13a47e91"
      },
      "cell_type": "code",
      "source": "random.shuffle(bands)\nbands = '\\n'.join(bands)\n\ntrain_df = bands[:round(len(bands)*0.8)]\ntest_df = bands[round(len(bands)*0.8):]",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "def68a754912b1ec4d0fe08dbe0ac69e804e2ae3"
      },
      "cell_type": "code",
      "source": "chars += '\\n'",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5dd3c8033a6639bb781ba18321fabd89e701f498"
      },
      "cell_type": "markdown",
      "source": "## Training"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c5b16014b918143fba58668fc2fcc5c2d9f4d8cf"
      },
      "cell_type": "code",
      "source": "class MyRNN(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(MyRNN, self).__init__()\n        \n        self.encoder = nn.Embedding(input_size, hidden_size)\n        self.rnn = nn.GRU(hidden_size, hidden_size, 1)\n        self.decoder = nn.Linear(hidden_size, output_size)      \n        self.hidden_size = hidden_size\n\n    def forward(self, input, hidden):\n        batch_size = input.size(0)\n        \n        embedding = self.encoder(input)\n        output, hidden = self.rnn(embedding.view(1, batch_size, -1), hidden)\n        output = self.decoder(output.view(batch_size, -1))\n        \n        return output, hidden\n\n    def init_hidden(self, batch_size):\n        return tt.zeros(1, batch_size, self.hidden_size)",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7c51eb9794ae94ec70c003b4b83ed4df0bfe0124"
      },
      "cell_type": "markdown",
      "source": "Наблюдение: если поставить большое значение chunk_length, названия начинают выглядеть лучше, что, в целом, логично."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "62b67ffbe017567ff9f98ec871069bfab2d35b0c"
      },
      "cell_type": "code",
      "source": "class Trainer:\n    def __init__(self, model, train_df, test_df, chars):\n        self.model = model\n        self.train_df = train_df\n        self.test_df = test_df\n        \n        self.chars = chars\n        \n        self.batch_size = 128\n        self.chunk_length = 256\n        \n        self.optimizer = tt.optim.Adam(self.model.parameters(), lr=0.01, weight_decay=1e-05)\n        self.criterion = nn.CrossEntropyLoss()\n    \n    def _char_tensor(self, string):\n        tensor = tt.zeros(len(string)).long()\n        \n        for ci in range(len(string)):\n            tensor[ci] = self.chars.index(string[ci])\n            \n        return tensor\n\n    def _randomize_data(self, data):\n        limit = len(data) - self.chunk_length\n        inp = tt.LongTensor(self.batch_size, self.chunk_length)\n        target = tt.LongTensor(self.batch_size, self.chunk_length)\n\n        for bi in range(self.batch_size):\n            start_index = random.randint(0, limit)\n            chunk = data[start_index : start_index + self.chunk_length + 1]\n            inp[bi] = self._char_tensor(chunk[:-1])\n            target[bi] = self._char_tensor(chunk[1:])\n\n        return inp, target\n\n    def _perplexity(self, x):\n        return 2 ** x\n    \n    def _train_epoch(self, inp, target, epoch):\n        self.model.train()\n        hidden = self.model.init_hidden(self.batch_size)\n        self.model.zero_grad()\n    \n        train_loss = 0\n        perplexities = []\n    \n        for ci in range(self.chunk_length):\n            self.optimizer.zero_grad()\n\n            output, hidden = self.model(inp[:,ci], hidden)\n            loss = self.criterion(output.view(self.batch_size, -1), target[:,ci])\n            perplexities.append(self._perplexity(loss.item()))\n\n            current_loss = loss.data.cpu().detach().item()\n            loss_smoothing = ci / (ci+1)\n            train_loss = loss_smoothing * train_loss + (1 - loss_smoothing) * current_loss\n\n        loss.backward()\n        self.optimizer.step()\n    \n        perplex = np.mean(perplexities)\n        \n        return train_loss, perple\n\n    def _test_epoch(self, inp, target):\n        self.model.eval()\n\n        epoch_loss, loss = 0, 0\n        perplexities = []\n\n        hidden = self.model.init_hidden(self.batch_size)\n\n        with tt.no_grad():\n            for ci in range(self.chunk_length):\n                output, hidden = self.model(inp[:,ci], hidden)\n                loss = self.criterion(output.view(self.batch_size, -1), target[:,ci])\n                perplexities.append(self._perplexity(loss.item()))\n                epoch_loss += loss.data.item()\n    \n        perplex = np.mean(perplexities)\n        \n        return epoch_loss / self.chunk_length, perplex\n\n\n    def nn_train(self, n_epochs, early_stopping):\n        print('Epoch\\tTrain loss\\tTest loss\\tTrain perplexity\\tTest perplexity')\n\n        best_epoch = None\n        prev_loss = 100500\n        es_epochs = 0\n        train_losses, test_losses = [], []\n    \n        for epoch in tqdm(range(n_epochs)):\n            try:\n                train_inp, train_target = self._randomize_data(self.train_df)\n                test_inp, test_target = self._randomize_data(self.test_df)\n\n                train_loss, train_per = self._train_epoch(train_inp, train_target, epoch)\n                test_loss, test_per = self._test_epoch(test_inp, test_target)\n\n                train_losses.append(train_loss)\n                test_losses.append(test_loss)\n\n                if epoch % 100 == 0 or epoch == n_epochs-1:\n                    print('%s \\t %.5f \\t %.5f \\t %.5f \\t %.5f' % (str(epoch),\n                                                                     train_loss,\n                                                                     test_loss,\n                                                                     train_per,\n                                                                     test_per))\n            except:\n                continue\n\n            if early_stopping > 0:\n                if test_loss > prev_loss:\n                    es_epochs += 1\n                else:\n                    es_epochs = 0\n                if es_epochs >= early_stopping:\n                    break\n                    \n                prev_loss = min(prev_loss, test_loss)\n\n    def generate_name(self):\n        stop_symbol = '\\n'\n        hidden = self.model.init_hidden(1)\n        prime_input = self._char_tensor(stop_symbol).unsqueeze(0)\n        predicted = ''\n\n        for p in range(len(stop_symbol) - 1):\n            _, hidden = self.model(prime_input[:,p], hidden)\n\n        inp = prime_input[:,-1]\n        predict_len = random.randint(20, 35)\n\n        for p in range(predict_len):\n            output, hidden = self.model(inp, hidden)\n            output_dist = output.data.view(-1).div(0.8).exp()\n            top_i = tt.multinomial(output_dist, 1)[0]\n            predicted_char = self.chars[top_i]\n\n            if predicted and predicted_char == '\\n':\n                break\n            else:\n                predicted += predicted_char\n                inp = self._char_tensor(predicted_char).unsqueeze(0)\n\n        return predicted\n",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a3da2e98a67f2f783059c61ecc9559c9a8b6c1cd"
      },
      "cell_type": "code",
      "source": "model = MyRNN(input_size=len(chars),\n              hidden_size=128, \n              output_size=len(chars))\n\ntrainer = Trainer(model, train_df, test_df, chars)",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c68d17b7fd652fa03018f06b8be44e137c6b5cc5"
      },
      "cell_type": "code",
      "source": "trainer.nn_train(1000, 300)",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Epoch\tTrain loss\tTest loss\tTrain perplexity\tTest perplexity\n",
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9881d52107cf4ccbbab3e1b1b9cc5a90"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2dd5fbf11742eaf9b8e8621e0d3d3ca0abb99a74"
      },
      "cell_type": "code",
      "source": "tt.save(model, 'model_hw7.pt')",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ab0eddda53ca73fe61354d0ac8b415b7e3d34775"
      },
      "cell_type": "markdown",
      "source": "## Evaluation"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bbe273dc5b48a3ad704df148aa1a512657dd0753"
      },
      "cell_type": "code",
      "source": "for x in range(10):\n    print(trainer.generate_name())",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Heetority\nCraing Death\nWanication\nCatalix\nTressompophitre\nTherort\nSaknacation\nMegor\nTors\n13Helge Dain\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "955dfaef1c1119272bae3c5acdad1de4b22ab954"
      },
      "cell_type": "markdown",
      "source": "Сгенерированные названия выглядят не особо осмысленно (хотя иногда попадаются реальные слова типа \"dead\" или \"demons\"), но довольно устрашающе."
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}