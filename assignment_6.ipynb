{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 6\n",
    "\n",
    "Develop RNN model in pytorch to solve the following problem:  \n",
    "    \n",
    "1. Detect sarcasm \n",
    "Data from https://www.kaggle.com/sherinclaudia/sarcastic-comments-on-reddit  \n",
    "Your quality metric = accuracy  \n",
    "Randomly select 20% of your data for test set. You can use it only for final perfomance estimation.   \n",
    " \n",
    "\n",
    "Remember, you can use GPU resourses in kaggle kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import gensim\n",
    "import pickle\n",
    "import torch as tt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchtext.data import Field, LabelField, BucketIterator, TabularDataset, Iterator, Dataset\n",
    "from string import punctuation\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>date</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>Trumpbart</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>2016-10-16 23:55:23</td>\n",
       "      <td>Yeah, I get that argument. At this point, I'd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>Shbshb906</td>\n",
       "      <td>nba</td>\n",
       "      <td>-4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-11</td>\n",
       "      <td>2016-11-01 00:24:10</td>\n",
       "      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>Creepeth</td>\n",
       "      <td>nfl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-09</td>\n",
       "      <td>2016-09-22 21:45:37</td>\n",
       "      <td>They're favored to win.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>This meme isn't funny none of the \"new york ni...</td>\n",
       "      <td>icebrotha</td>\n",
       "      <td>BlackPeopleTwitter</td>\n",
       "      <td>-8</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>2016-10-18 21:03:47</td>\n",
       "      <td>deadass don't kill my buzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I could use one of those tools.</td>\n",
       "      <td>cush2push</td>\n",
       "      <td>MaddenUltimateTeam</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-12</td>\n",
       "      <td>2016-12-30 17:00:13</td>\n",
       "      <td>Yep can confirm I saw the tool they use for th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            comment     author  \\\n",
       "0      0                                         NC and NH.  Trumpbart   \n",
       "1      0  You do know west teams play against west teams...  Shbshb906   \n",
       "2      0  They were underdogs earlier today, but since G...   Creepeth   \n",
       "3      0  This meme isn't funny none of the \"new york ni...  icebrotha   \n",
       "4      0                    I could use one of those tools.  cush2push   \n",
       "\n",
       "            subreddit  score  ups  downs     date          created_utc  \\\n",
       "0            politics      2   -1     -1  2016-10  2016-10-16 23:55:23   \n",
       "1                 nba     -4   -1     -1  2016-11  2016-11-01 00:24:10   \n",
       "2                 nfl      3    3      0  2016-09  2016-09-22 21:45:37   \n",
       "3  BlackPeopleTwitter     -8   -1     -1  2016-10  2016-10-18 21:03:47   \n",
       "4  MaddenUltimateTeam      6   -1     -1  2016-12  2016-12-30 17:00:13   \n",
       "\n",
       "                                      parent_comment  \n",
       "0  Yeah, I get that argument. At this point, I'd ...  \n",
       "1  The blazers and Mavericks (The wests 5 and 6 s...  \n",
       "2                            They're favored to win.  \n",
       "3                         deadass don't kill my buzz  \n",
       "4  Yep can confirm I saw the tool they use for th...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train-balanced-sarcasm.csv',  encoding='ISO-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return [tok for tok in nltk.tokenize.wordpunct_tokenize(text) if tok not in punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {'sarcastic': 0, 'common': 1}\n",
    "\n",
    "TEXT = Field(include_lengths=True, batch_first=True, \n",
    "             tokenize=tokenizer,\n",
    "             eos_token='<eos>',\n",
    "             lower=True,\n",
    "             stop_words=nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "LABEL = LabelField(dtype=tt.int64, use_vocab=True, preprocessing=lambda x: classes[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tb_df = TabularDataset('train-balanced-sarcasm.csv',\n",
    "                       format='csv',\n",
    "                       fields=[('label', LABEL), ('comment', TEXT), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None)],\n",
    "                       skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEXT.build_vocab(tb_df, min_freq=10, vectors=\"glove.6B.100d\")\n",
    "len(TEXT.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABEL.build_vocab(tb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = tb_df.split(0.7, stratified=True)\n",
    "train, valid = train.split(0.7, stratified=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyRNN(nn.Module):   \n",
    "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
    "        super(MyRNN, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_size=embed_size,\n",
    "                           hidden_size=hidden_size,\n",
    "                           bidirectional=True,\n",
    "                           batch_first=True,\n",
    "                          )\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size * 2 *2, 3)\n",
    "        \n",
    "        \n",
    "    def forward(self, batch):       \n",
    "        x, x_lengths = batch.comment\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "\n",
    "        if x_lengths is not None:\n",
    "            x_lengths = x_lengths.view(-1).tolist()\n",
    "            x = nn.utils.rnn.pack_padded_sequence(x, x_lengths, batch_first=True)\n",
    "            \n",
    "        _, (hidden, cell) = self.rnn(x)\n",
    "        \n",
    "        hidden = hidden.transpose(0,1)\n",
    "        cell = cell.transpose(0,1)\n",
    "        hidden = hidden.contiguous().view(hidden.size(0),-1)\n",
    "        cell = cell.contiguous().view(cell.size(0),-1)\n",
    "        x = tt.cat([hidden, cell], dim=1).squeeze(1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, train_iterator, test_iterator, valid_iterator):\n",
    "        self.model = model\n",
    "        self.train_iterator = train_iterator\n",
    "        self.test_iterator = test_iterator\n",
    "        self.valid_iterator = valid_iterator\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.model.parameters())\n",
    "        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def _train_epoch(self, iterator, curr_epoch):\n",
    "        self.model.train()\n",
    "        running_loss = 0\n",
    "\n",
    "        n_batches = len(iterator)\n",
    "        iterator = tqdm_notebook(iterator, total=n_batches, desc='epoch %d' % (curr_epoch), leave=True)\n",
    "\n",
    "        for i, batch in enumerate(iterator):\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            pred = self.model(batch)\n",
    "            loss = self.criterion(pred, batch.label)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            curr_loss = loss.data.cpu().detach().item()\n",
    "\n",
    "            loss_smoothing = i / (i+1)\n",
    "            running_loss = loss_smoothing * running_loss + (1 - loss_smoothing) * curr_loss\n",
    "\n",
    "            iterator.set_postfix(loss='%.5f' % running_loss)\n",
    "\n",
    "        return running_loss\n",
    "    \n",
    "    def _test_epoch(iterator):\n",
    "        self.model.eval()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        n_batches = len(iterator)\n",
    "        \n",
    "        with tt.no_grad():\n",
    "            for batch in iterator:\n",
    "                pred = model(batch)\n",
    "                loss = self.criterion(pred, batch.label)\n",
    "                epoch_loss += loss.data.item()\n",
    "\n",
    "        return epoch_loss / n_batches\n",
    "\n",
    "    def nn_train(self, n_epochs):\n",
    "        early_stopping = 0\n",
    "        prev_loss = 100500\n",
    "        es_epochs = 0\n",
    "        best_epoch = None\n",
    "        history = pd.DataFrame()\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            train_loss = _train_epoch(self.train_iterator, epoch)\n",
    "            valid_loss = _test_epoch(self.valid_iterator)\n",
    "\n",
    "            valid_loss = valid_loss\n",
    "            print('validation loss %.5f' % valid_loss)\n",
    "\n",
    "            record = {'epoch': epoch, 'train_loss': train_loss, 'valid_loss': valid_loss}\n",
    "            history = history.append(record, ignore_index=True)\n",
    "\n",
    "            if early_stopping > 0:\n",
    "                if valid_loss > prev_loss:\n",
    "                    es_epochs += 1\n",
    "                else:\n",
    "                    es_epochs = 0\n",
    "\n",
    "                if es_epochs >= early_stopping:\n",
    "                    best_epoch = history[history.valid_loss == history.valid_loss.min()].iloc[0]\n",
    "                    print('Early stopping! best epoch: %d val %.5f' % (best_epoch['epoch'], best_epoch['valid_loss']))\n",
    "                    break\n",
    "\n",
    "                prev_loss = min(prev_loss, valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tt.cuda.empty_cache()\n",
    "batch_size = 32\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits((train, valid, test),\n",
    "                                                                      batch_sizes=(batch_size, batch_size, batch_size),\n",
    "                                                                      shuffle=True,\n",
    "                                                                      sort_key=lambda x: len(x.comment),\n",
    "                                                                      sort_within_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = MyRNN(len(TEXT.vocab.itos),\n",
    "              embed_size=100,\n",
    "              hidden_size=128,\n",
    "              )\n",
    "\n",
    "trainer = Trainer(model, train_iterator, test_iterator, valid_iterator)\n",
    "trainer.train(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
